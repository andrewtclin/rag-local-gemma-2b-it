{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369b5917",
   "metadata": {},
   "source": [
    "# Create & Run a Local RAG Pipeline from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3496144",
   "metadata": {},
   "source": [
    "## What is RAG?\n",
    "\n",
    "RAG stands for Retrieval Augmented Generation.\n",
    "\n",
    "The goal of RAG is to take information and pass it to an LLM, so it can generate outputs based on that information.\n",
    "\n",
    "* Retrieval - Find relevant information given a query, e.g. \"What are the macronutrients & what do they do?\" -> retrieves passages of text related to the macronutrients from a nutrition textbook.\n",
    "\n",
    "* Augmented - We want to take the relevant information & augment our input (prompt) to an LLM with that relevant information.\n",
    "\n",
    "* Generation - Take the first 2 steps & pass them to an LLM for generative outputs.\n",
    "\n",
    "Where RAG came from - Facebook / Meta AI Paper: *Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks*\n",
    "> This work offers several positive societal benefits over previous work: the fact that it is more strongly grounded in real factual knowledge (in this case Wikipedia) makes it “hallucinate” less with generations that are more factual, and offers more control and interpretability. RAG could be employed in a wide variety of scenarios with direct benefit to society, for example by endowing it with a medical index and asking it open-domain questions on that topic, or by helping people be more effective at their jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f4675e",
   "metadata": {},
   "source": [
    "## Why RAG?\n",
    "\n",
    "The main goal of RAG is to improve the generation outputs of LLMs.\n",
    "\n",
    "1. Prevent hallucinations - LLMs are incredibly good at generating good *looking* text, however, this text doesn't mean that it is factual. RAG can help LLMs generate information based on relevant passages that are factual.\n",
    "\n",
    "2. Work with custom data - Many base LLMs are trained with internet-scale data. This means they have a fairly good understanding of language in general. However, it also does a lot of their responses can be generic in nature. RAG helps to create specific responses based on specific documents (e.g. your own companies customer support documents)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6591eb51",
   "metadata": {},
   "source": [
    "## What can RAG be used for?\n",
    "\n",
    "* Customer Support Q&A Chat - Treat your existing customer support documents as a resource and when a customer asks a question, you could have a retrieval system, retrieve relevant documentation snippets & then have a LLM craft those snippets into an answer. Think of this as a \"chatbot for your documentation\".\n",
    "\n",
    "* Email Chain Analysis - Let's say you are a large insurance company & you have chains and chains of emails of customer claims. You could use a RAG pipeline to find relevant information from those emails & then use an LLM to process that information into structured data.\n",
    "\n",
    "* Company Interval Documentation Chat\n",
    "\n",
    "* Textbook Q&A - Let's say you are a nutrition student and you've got a 1200 pages textbook read, you could build a RAG pipeline to go through the textbook and find relevant passages to the questions you have.\n",
    "\n",
    "Common theme here: Take your relevant documents to a query & process them with an LLM.\n",
    "\n",
    "From this angle, consider LLM as a calculator for words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c181070c",
   "metadata": {},
   "source": [
    "## Why Local?\n",
    "\n",
    "Fun. \n",
    "\n",
    "Privacy, Speed, Cost.\n",
    "\n",
    "* Privacy - If you have private documentation, maybe you don't want to send that to an API. You want to setup an LLM and run it on your own hardware.\n",
    "* Speed - Whenever you use an API, you have to send some kind of data across the internet. This takes time. Running locally means we don't have to wait for transfers of data.\n",
    "* Cost - If you own your hardware, the cost is paid. It may have a large cost to begin with. But overtime, you don't have to keep paying API fees.\n",
    "* No Vendor Lock-in - If you run your own software/ hardware. If Large company shuts down tomorrow, you can still run your business."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c5098a",
   "metadata": {},
   "source": [
    "## What Will Be Built?\n",
    "\n",
    "Build NutriChat to \"chat with a nutrition document\".\n",
    "\n",
    "Specifically:\n",
    "\n",
    "1. Open a PDF document (you could use almost any PDF here or even a collection of PDFs).\n",
    "2. Format the text of the PDF textbook ready for an embedding model.\n",
    "3. Embbed all of the chunks of text in the textbook, and turn them into numerical representations (embeddings) which can store for later.\n",
    "4. Build a retrieval system that uses vector search to find relevant chunk of text based on a query.\n",
    "5. Create a prompt that incorporates the retrieved pieces of text.\n",
    "6. Generate an answer to a query based on the passages of the textbook with an LLM.\n",
    "\n",
    "All Locally!\n",
    "\n",
    "1. Steps 1 - 3: Document Preprocessing & Embedding Creation.\n",
    "2. Steps 4 - 6: Search & Answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfb01dd",
   "metadata": {},
   "source": [
    "## 1. Document / Text Preprocessing & Embedding Creation\n",
    "\n",
    "Ingredients:\n",
    "* PDF document of choice (note: this could be almost any kind of document, just that PDFs are focused for now).\n",
    "* Embedding model of choice\n",
    "\n",
    "Steps:\n",
    "1. Import PDF Document.\n",
    "2. Preprocess Text for Embedding (e.g. Split into Chunks of Sentences).\n",
    "3. Embbed Text Chunks with Embedding Model.\n",
    "4. Save Embeddings to File for Later (Embeddings will store on files for many years or until you lose your hard drive)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4832a118",
   "metadata": {},
   "source": [
    "## Import PDF Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b390d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ab4cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] File does not exist, downloading...\n",
      "[INFO] The file has been downloaded & saved as human-nutrition-text.pdf.\n"
     ]
    }
   ],
   "source": [
    "# path to document\n",
    "pdf_path = 'human-nutrition-text.pdf'\n",
    "\n",
    "# download PDF\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(f'[INFO] File does not exist, downloading...')\n",
    "    \n",
    "    # url of the pdf\n",
    "    url = 'https://pressbooks.oer.hawaii.edu/humannutrition2/open/download?type=pdf'\n",
    "    \n",
    "    # the local file name to save the downloaded file\n",
    "    fname = pdf_path\n",
    "    \n",
    "    # GET request\n",
    "    res = requests.get(url)\n",
    "    \n",
    "    # check if the request is successful\n",
    "    if res.status_code == 200:\n",
    "        # open the file & save it\n",
    "        with open(fname, 'wb') as f:\n",
    "            f.write(res.content)\n",
    "        print(f'[INFO] The file has been downloaded & saved as {fname}.')\n",
    "    else:\n",
    "        print(f'[INFO] Failed to download the file. Status Code: {res.status_code}')\n",
    "else:\n",
    "    print(f'[INFO] File {pdf_path} exists.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6e0be",
   "metadata": {},
   "source": [
    "PDF is now available, let's open it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7aa0411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d497df10b8a84574ab73e67396be9b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'page_no': -41,\n",
       "  'page_char_cnt': 29,\n",
       "  'page_word_cnt': 4,\n",
       "  'page_sentence_cnt_raw': 1,\n",
       "  'page_token_cnt': 7.25,\n",
       "  'text': 'Human Nutrition: 2020 Edition'},\n",
       " {'page_no': -40,\n",
       "  'page_char_cnt': 0,\n",
       "  'page_word_cnt': 1,\n",
       "  'page_sentence_cnt_raw': 1,\n",
       "  'page_token_cnt': 0.0,\n",
       "  'text': ''}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz # from PyMuPDF\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "def text_formatter(text: str) -> str:\n",
    "    '''Performs minor formatting on text.'''\n",
    "    cleaned_text = text.replace('\\n', ' ').strip()\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "def open_and_read_pdf(path: str) -> list[dict]:\n",
    "    doc = fitz.open(path)\n",
    "    pages_and_texts = []\n",
    "    \n",
    "    for page_no, page in tqdm(enumerate(doc)):\n",
    "        text = page.get_text()\n",
    "        text = text_formatter(text=text)\n",
    "        pages_and_texts.append({'page_no': page_no - 41,\n",
    "                                'page_char_cnt': len(text),\n",
    "                                'page_word_cnt': len(text.split(' ')),\n",
    "                                'page_sentence_cnt_raw': len(text.split('. ')),\n",
    "                                'page_token_cnt': len(text) / 4, # 1 token ~ 4 chars\n",
    "                                'text': text})\n",
    "    return pages_and_texts\n",
    "\n",
    "pages_and_texts = open_and_read_pdf(path=pdf_path)\n",
    "pages_and_texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c304778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_no': 404,\n",
       "  'page_char_cnt': 116,\n",
       "  'page_word_cnt': 16,\n",
       "  'page_sentence_cnt_raw': 1,\n",
       "  'page_token_cnt': 29.0,\n",
       "  'text': 'view it online here:  http:/ /pressbooks.oer.hawaii.edu/ humannutrition2/?p=268  404  |  Diseases Involving Proteins'},\n",
       " {'page_no': 1090,\n",
       "  'page_char_cnt': 536,\n",
       "  'page_word_cnt': 98,\n",
       "  'page_sentence_cnt_raw': 6,\n",
       "  'page_token_cnt': 134.0,\n",
       "  'text': 'Image by  BruceBlaus/  CC BY 4.0  When the vertebral bone tissue is weakened, it can cause the spine  to curve. The increase in spine curvature not only causes pain,  but also decreases a person’s height. Curvature of the upper spine  produces what is called Dowager’s hump, also known as kyphosis.  Severe upper-spine deformity can compress the chest cavity and  cause difficulty breathing. It may also cause abdominal pain and loss  of appetite because of the increased pressure on the abdomen.  1090  |  Nutrition, Health and Disease'},\n",
       " {'page_no': 166,\n",
       "  'page_char_cnt': 1783,\n",
       "  'page_word_cnt': 315,\n",
       "  'page_sentence_cnt_raw': 21,\n",
       "  'page_token_cnt': 445.75,\n",
       "  'text': 'Thirst Mechanism: Why Do We Drink?  Thirst is an osmoregulatory mechanism to increase water input.  The thirst mechanism is activated in response to changes in water  volume in the blood, but is even more sensitive to changes in blood  osmolality. Blood osmolality is primarily driven by the concentration  of sodium cations. The urge to drink results from a complex  interplay of hormones and neuronal responses that coordinate to  increase water input and contribute toward fluid balance and  composition in the body. The “thirst center” is contained within  the hypothalamus, a portion of the brain that lies just above the  brainstem. In older people the thirst mechanism is not as responsive  and as we age there is a higher risk for dehydration. Thirst happens  in the following sequence of physiological events:  1. Receptor proteins in the kidney, heart, and hypothalamus  detect decreased fluid volume or increased sodium  concentration in the blood.  2. Hormonal and neural messages are relayed to the brain’s thirst  center in the hypothalamus.  The hypothalamus sends neural signals to higher sensory areas  in the cortex of the brain, stimulating the conscious thought to  drink.  3. Fluids are consumed.  4. Receptors in the mouth and stomach detect mechanical  movements involved with fluid ingestion.  5. Neural signals are sent to the brain and the thirst mechanism  is shut off.  The physiological control of thirst is the backup mechanism to  increase water input. Fluid intake is controlled primarily by  conscious eating and drinking habits dependent on social and  cultural influences. For example, you might have a habit of drinking  a glass of orange juice and eating a bowl of cereal every morning  before school or work.  166  |  Regulation of Water Balance'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.sample(pages_and_texts, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96f1d7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_no</th>\n",
       "      <th>page_char_cnt</th>\n",
       "      <th>page_word_cnt</th>\n",
       "      <th>page_sentence_cnt_raw</th>\n",
       "      <th>page_token_cnt</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-41</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7.25</td>\n",
       "      <td>Human Nutrition: 2020 Edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-39</td>\n",
       "      <td>320</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>80.00</td>\n",
       "      <td>Human Nutrition: 2020  Edition  UNIVERSITY OF ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-38</td>\n",
       "      <td>212</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>53.00</td>\n",
       "      <td>Human Nutrition: 2020 Edition by University of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-37</td>\n",
       "      <td>797</td>\n",
       "      <td>145</td>\n",
       "      <td>2</td>\n",
       "      <td>199.25</td>\n",
       "      <td>Contents  Preface  University of Hawai‘i at Mā...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_no  page_char_cnt  page_word_cnt  page_sentence_cnt_raw  \\\n",
       "0      -41             29              4                      1   \n",
       "1      -40              0              1                      1   \n",
       "2      -39            320             54                      1   \n",
       "3      -38            212             32                      1   \n",
       "4      -37            797            145                      2   \n",
       "\n",
       "   page_token_cnt                                               text  \n",
       "0            7.25                      Human Nutrition: 2020 Edition  \n",
       "1            0.00                                                     \n",
       "2           80.00  Human Nutrition: 2020  Edition  UNIVERSITY OF ...  \n",
       "3           53.00  Human Nutrition: 2020 Edition by University of...  \n",
       "4          199.25  Contents  Preface  University of Hawai‘i at Mā...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "226ce042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_no</th>\n",
       "      <th>page_char_cnt</th>\n",
       "      <th>page_word_cnt</th>\n",
       "      <th>page_sentence_cnt_raw</th>\n",
       "      <th>page_token_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.59</td>\n",
       "      <td>198.89</td>\n",
       "      <td>9.97</td>\n",
       "      <td>287.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.44</td>\n",
       "      <td>95.75</td>\n",
       "      <td>6.19</td>\n",
       "      <td>140.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.75</td>\n",
       "      <td>134.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>190.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1232.50</td>\n",
       "      <td>215.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>308.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1605.25</td>\n",
       "      <td>271.25</td>\n",
       "      <td>14.00</td>\n",
       "      <td>401.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>429.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>577.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_no  page_char_cnt  page_word_cnt  page_sentence_cnt_raw  \\\n",
       "count  1208.00        1208.00        1208.00                1208.00   \n",
       "mean    562.50        1148.59         198.89                   9.97   \n",
       "std     348.86         560.44          95.75                   6.19   \n",
       "min     -41.00           0.00           1.00                   1.00   \n",
       "25%     260.75         762.75         134.00                   4.00   \n",
       "50%     562.50        1232.50         215.00                  10.00   \n",
       "75%     864.25        1605.25         271.25                  14.00   \n",
       "max    1166.00        2308.00         429.00                  32.00   \n",
       "\n",
       "       page_token_cnt  \n",
       "count         1208.00  \n",
       "mean           287.15  \n",
       "std            140.11  \n",
       "min              0.00  \n",
       "25%            190.69  \n",
       "50%            308.12  \n",
       "75%            401.31  \n",
       "max            577.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efa7d67",
   "metadata": {},
   "source": [
    "Why would we care about token count?\n",
    "\n",
    "Token count is important to think about because:\n",
    "\n",
    "1. Embedding models don't deal with infinite tokens.\n",
    "2. LLMs don't deal with infinite tokens.\n",
    "\n",
    "For example, an embedding model may have been trained to embbed sequences of 384 tokens into numerical space (sentence-transformers `all-mpnet-base-v2`, see: https://www.sbert.net/docs/sentence_transformer/pretrained_models.html)\n",
    "\n",
    "As for LLMs, they can't accept infinite tokens in their context window."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd9d8db",
   "metadata": {},
   "source": [
    "## Further Text Preprocessing\n",
    "\n",
    "Splitting pages into sentences.\n",
    "\n",
    "2 Ways to do this:\n",
    "\n",
    "1. Done this by splitting on `'.'`.\n",
    "2. Do this by NLP library, such as spaCy and nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44d853f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is a sentence., This is another sentence., I like elephants.]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "# Add a sentencizer pipeline (turning texts into sentences)\n",
    "nlp.add_pipe('sentencizer')\n",
    "\n",
    "# Create document instance as an example\n",
    "doc = nlp('This is a sentence. This is another sentence. I like elephants.')\n",
    "assert len(list(doc.sents)) == 3\n",
    "\n",
    "# Print sentences split\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b50c81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_no': -41,\n",
       " 'page_char_cnt': 29,\n",
       " 'page_word_cnt': 4,\n",
       " 'page_sentence_cnt_raw': 1,\n",
       " 'page_token_cnt': 7.25,\n",
       " 'text': 'Human Nutrition: 2020 Edition'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aff9f8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b21fafc5344a28abcd6a71f5db47eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in tqdm(pages_and_texts):\n",
    "    item['sentences'] = list(nlp(item['text']).sents)\n",
    "\n",
    "    # Make sure all sentences are string (default type is spaCy data type)\n",
    "    item['sentences'] = [str(sentence) for sentence in item['sentences']]\n",
    "    \n",
    "    # Count the sentences\n",
    "    item['page_sentence_cnt_spacy'] = len(item['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c288e1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_no': 196,\n",
       "  'page_char_cnt': 1598,\n",
       "  'page_word_cnt': 279,\n",
       "  'page_sentence_cnt_raw': 13,\n",
       "  'page_token_cnt': 399.5,\n",
       "  'text': 'Potassium also is involved in protein synthesis, energy metabolism,  and platelet function, and acts as a buffer in blood, playing a role in  acid-base balance.  Imbalances of Potassium  Insufficient potassium levels in the body (hypokalemia) can be  caused by a low dietary intake of potassium or by high sodium  intakes, but more commonly it results from medications that  increase water excretion, mainly diuretics. The signs and symptoms  of hypokalemia are related to the functions of potassium in nerve  cells and consequently skeletal and smooth-muscle contraction.  The signs and symptoms include muscle weakness and cramps,  respiratory distress, and constipation. Severe potassium depletion  can cause the heart to have abnormal contractions and can even  be fatal. High levels of potassium in the blood, or hyperkalemia,  also affects the heart. It is a silent condition as it often displays  no signs or symptoms. Extremely high levels of potassium in the  blood disrupt the electrical impulses that stimulate the heart and  can cause the heart to stop. Hyperkalemia is usually the result of  kidney dysfunction.  Needs and Dietary Sources of Potassium  The IOM based their AIs for potassium on the levels associated with  a decrease in blood pressure, a reduction in salt sensitivity, and a  minimal risk of kidney stones. For adult male and females above  the age of nineteen, the adequate intake for potassium is 4,700  grams per day. The AIs for other age groups are listed in Table 3.8  “Adequate Intakes for Potassium”.  Table 3.8 Adequate Intakes for Potassium  196  |  Potassium',\n",
       "  'sentences': ['Potassium also is involved in protein synthesis, energy metabolism,  and platelet function, and acts as a buffer in blood, playing a role in  acid-base balance.',\n",
       "   ' Imbalances of Potassium  Insufficient potassium levels in the body (hypokalemia) can be  caused by a low dietary intake of potassium or by high sodium  intakes, but more commonly it results from medications that  increase water excretion, mainly diuretics.',\n",
       "   'The signs and symptoms  of hypokalemia are related to the functions of potassium in nerve  cells and consequently skeletal and smooth-muscle contraction.',\n",
       "   ' The signs and symptoms include muscle weakness and cramps,  respiratory distress, and constipation.',\n",
       "   'Severe potassium depletion  can cause the heart to have abnormal contractions and can even  be fatal.',\n",
       "   'High levels of potassium in the blood, or hyperkalemia,  also affects the heart.',\n",
       "   'It is a silent condition as it often displays  no signs or symptoms.',\n",
       "   'Extremely high levels of potassium in the  blood disrupt the electrical impulses that stimulate the heart and  can cause the heart to stop.',\n",
       "   'Hyperkalemia is usually the result of  kidney dysfunction.',\n",
       "   ' Needs and Dietary Sources of Potassium  The IOM based their AIs for potassium on the levels associated with  a decrease in blood pressure, a reduction in salt sensitivity, and a  minimal risk of kidney stones.',\n",
       "   'For adult male and females above  the age of nineteen, the adequate intake for potassium is 4,700  grams per day.',\n",
       "   'The AIs for other age groups are listed in Table 3.8  “Adequate Intakes for Potassium”.',\n",
       "   ' Table 3.8 Adequate Intakes for Potassium  196  |  Potassium'],\n",
       "  'page_sentence_cnt_spacy': 13}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "241b4946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_no</th>\n",
       "      <th>page_char_cnt</th>\n",
       "      <th>page_word_cnt</th>\n",
       "      <th>page_sentence_cnt_raw</th>\n",
       "      <th>page_token_cnt</th>\n",
       "      <th>page_sentence_cnt_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.59</td>\n",
       "      <td>198.89</td>\n",
       "      <td>9.97</td>\n",
       "      <td>287.15</td>\n",
       "      <td>10.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.44</td>\n",
       "      <td>95.75</td>\n",
       "      <td>6.19</td>\n",
       "      <td>140.11</td>\n",
       "      <td>6.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.75</td>\n",
       "      <td>134.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>190.69</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1232.50</td>\n",
       "      <td>215.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>308.12</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1605.25</td>\n",
       "      <td>271.25</td>\n",
       "      <td>14.00</td>\n",
       "      <td>401.31</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>429.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>577.00</td>\n",
       "      <td>28.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_no  page_char_cnt  page_word_cnt  page_sentence_cnt_raw  \\\n",
       "count  1208.00        1208.00        1208.00                1208.00   \n",
       "mean    562.50        1148.59         198.89                   9.97   \n",
       "std     348.86         560.44          95.75                   6.19   \n",
       "min     -41.00           0.00           1.00                   1.00   \n",
       "25%     260.75         762.75         134.00                   4.00   \n",
       "50%     562.50        1232.50         215.00                  10.00   \n",
       "75%     864.25        1605.25         271.25                  14.00   \n",
       "max    1166.00        2308.00         429.00                  32.00   \n",
       "\n",
       "       page_token_cnt  page_sentence_cnt_spacy  \n",
       "count         1208.00                  1208.00  \n",
       "mean           287.15                    10.32  \n",
       "std            140.11                     6.30  \n",
       "min              0.00                     0.00  \n",
       "25%            190.69                     5.00  \n",
       "50%            308.12                    10.00  \n",
       "75%            401.31                    15.00  \n",
       "max            577.00                    28.00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87d5bcd",
   "metadata": {},
   "source": [
    "### Chunking our sentences together\n",
    "\n",
    "The concept of splitting larger pieces of texts into smaller ones, often refer to as `text splitting` or `chunking`.\n",
    "\n",
    "There is no 100% of correct way to do this - experiment!\n",
    "\n",
    "To keep it simple, it will split into groups of 10 sentences.\n",
    "\n",
    "There are frameworks such as `langchain` which can help with this, but we will use `python` for now.\n",
    "- https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/\n",
    "\n",
    "Why do we do this:\n",
    "1. So the texts are easier to filter (smaller group of texts can be easier to inspect than large passages of texts).\n",
    "2. So the text chunks can fit into the embedding model of context. (eg. 384 tokens has a limit).\n",
    "3. So the contexts passed into LLM can be more specific and focused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c248b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:general]",
   "language": "python",
   "name": "conda-env-general-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
