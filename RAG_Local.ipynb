{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369b5917",
   "metadata": {},
   "source": [
    "# Create & Run a Local RAG Pipeline from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3496144",
   "metadata": {},
   "source": [
    "## What is RAG?\n",
    "\n",
    "RAG stands for Retrieval Augmented Generation.\n",
    "\n",
    "The goal of RAG is to take information and pass it to an LLM, so it can generate outputs based on that information.\n",
    "\n",
    "* Retrieval - Find relevant information given a query, e.g. \"What are the macronutrients & what do they do?\" -> retrieves passages of text related to the macronutrients from a nutrition textbook.\n",
    "\n",
    "* Augmented - We want to take the relevant information & augment our input (prompt) to an LLM with that relevant information.\n",
    "\n",
    "* Generation - Take the first 2 steps & pass them to an LLM for generative outputs.\n",
    "\n",
    "Where RAG came from - Facebook / Meta AI Paper: *Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks*\n",
    "> This work offers several positive societal benefits over previous work: the fact that it is more strongly grounded in real factual knowledge (in this case Wikipedia) makes it “hallucinate” less with generations that are more factual, and offers more control and interpretability. RAG could be employed in a wide variety of scenarios with direct benefit to society, for example by endowing it with a medical index and asking it open-domain questions on that topic, or by helping people be more effective at their jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f4675e",
   "metadata": {},
   "source": [
    "## Why RAG?\n",
    "\n",
    "The main goal of RAG is to improve the generation outputs of LLMs.\n",
    "\n",
    "1. Prevent hallucinations - LLMs are incredibly good at generating good *looking* text, however, this text doesn't mean that it is factual. RAG can help LLMs generate information based on relevant passages that are factual.\n",
    "\n",
    "2. Work with custom data - Many base LLMs are trained with internet-scale data. This means they have a fairly good understanding of language in general. However, it also does a lot of their responses can be generic in nature. RAG helps to create specific responses based on specific documents (e.g. your own companies customer support documents)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6591eb51",
   "metadata": {},
   "source": [
    "## What can RAG be used for?\n",
    "\n",
    "* Customer Support Q&A Chat - Treat your existing customer support documents as a resource and when a customer asks a question, you could have a retrieval system, retrieve relevant documentation snippets & then have a LLM craft those snippets into an answer. Think of this as a \"chatbot for your documentation\".\n",
    "\n",
    "* Email Chain Analysis - Let's say you are a large insurance company & you have chains and chains of emails of customer claims. You could use a RAG pipeline to find relevant information from those emails & then use an LLM to process that information into structured data.\n",
    "\n",
    "* Company Interval Documentation Chat\n",
    "\n",
    "* Textbook Q&A - Let's say you are a nutrition student and you've got a 1200 pages textbook read, you could build a RAG pipeline to go through the textbook and find relevant passages to the questions you have.\n",
    "\n",
    "Common theme here: Take your relevant documents to a query & process them with an LLM.\n",
    "\n",
    "From this angle, consider LLM as a calculator for words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c181070c",
   "metadata": {},
   "source": [
    "## Why Local?\n",
    "\n",
    "Fun. \n",
    "\n",
    "Privacy, Speed, Cost.\n",
    "\n",
    "* Privacy - If you have private documentation, maybe you don't want to send that to an API. You want to setup an LLM and run it on your own hardware.\n",
    "* Speed - Whenever you use an API, you have to send some kind of data across the internet. This takes time. Running locally means we don't have to wait for transfers of data.\n",
    "* Cost - If you own your hardware, the cost is paid. It may have a large cost to begin with. But overtime, you don't have to keep paying API fees.\n",
    "* No Vendor Lock-in - If you run your own software/ hardware. If Large company shuts down tomorrow, you can still run your business."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c5098a",
   "metadata": {},
   "source": [
    "## What Will Be Built?\n",
    "\n",
    "Build NutriChat to \"chat with a nutrition document\".\n",
    "\n",
    "Specifically:\n",
    "\n",
    "1. Open a PDF document (you could use almost any PDF here or even a collection of PDFs).\n",
    "2. Format the text of the PDF textbook ready for an embedding model.\n",
    "3. Embbed all of the chunks of text in the textbook, and turn them into numerical representations (embeddings) which can store for later.\n",
    "4. Build a retrieval system that uses vector search to find relevant chunk of text based on a query.\n",
    "5. Create a prompt that incorporates the retrieved pieces of text.\n",
    "6. Generate an answer to a query based on the passages of the textbook with an LLM.\n",
    "\n",
    "All Locally!\n",
    "\n",
    "1. Steps 1 - 3: Document Preprocessing & Embedding Creation.\n",
    "2. Steps 4 - 6: Search & Answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfb01dd",
   "metadata": {},
   "source": [
    "## 1. Document / Text Preprocessing & Embedding Creation\n",
    "\n",
    "Ingredients:\n",
    "* PDF document of choice (note: this could be almost any kind of document, just that PDFs are focused for now).\n",
    "* Embedding model of choice\n",
    "\n",
    "Steps:\n",
    "1. Import PDF Document.\n",
    "2. Preprocess Text for Embedding (e.g. Split into Chunks of Sentences).\n",
    "3. Embbed Text Chunks with Embedding Model.\n",
    "4. Save Embeddings to File for Later (Embeddings will store on files for many years or until you lose your hard drive)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4832a118",
   "metadata": {},
   "source": [
    "## Import PDF Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b390d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ab4cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] File does not exist, download...\n",
      "[INFO] The file has been downloaded & saved as human-nutrition-text.pdf.\n"
     ]
    }
   ],
   "source": [
    "# path to document\n",
    "pdf_path = 'human-nutrition-text.pdf'\n",
    "\n",
    "# download PDF\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(f'[INFO] File does not exist, downloading...')\n",
    "    \n",
    "    # url of the pdf\n",
    "    url = 'https://pressbooks.oer.hawaii.edu/humannutrition2/open/download?type=pdf'\n",
    "    \n",
    "    # the local file name to save the downloaded file\n",
    "    fname = pdf_path\n",
    "    \n",
    "    # GET request\n",
    "    res = requests.get(url)\n",
    "    \n",
    "    # check if the request is successful\n",
    "    if res.status_code == 200:\n",
    "        # open the file & save it\n",
    "        with open(fname, 'wb') as f:\n",
    "            f.write(res.content)\n",
    "        print(f'[INFO] The file has been downloaded & saved as {fname}.')\n",
    "    else:\n",
    "        print(f'[INFO] Failed to download the file. Status Code: {res.status_code}')\n",
    "else:\n",
    "    print(f'[INFO] File {pdf_path} exists.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6e0be",
   "metadata": {},
   "source": [
    "PDF is now available, let's open it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa0411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz # from PyMuPDF\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "def text_formatter(text: str) -> str:\n",
    "    '''Performs minor formatting on text.'''\n",
    "    cleaned_text = text.replace('\\n', ' ').strip()\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "def open_and_read_pdf(path: str) -> list[dict]:\n",
    "    doc = fitz.open(path)\n",
    "    pages_and_texts = []\n",
    "    \n",
    "    for page_no, page in tqdm(enumerate(doc)):\n",
    "        text = page.get_text()\n",
    "        text = text_formatter(text=text)\n",
    "        pages_and_texts.append({'page_no': page_no - 41,\n",
    "                                'page_char_cnt': len(text),\n",
    "                                'page_word_cnt': len(text.split(' ')),\n",
    "                                'page_sentence_cnt_raw': len(text.split('. ')),\n",
    "                                'page_token_cnt': len(text) / 4 # 1 token ~ 4 chars})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:general]",
   "language": "python",
   "name": "conda-env-general-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
